{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "#SK learn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical for nn\n",
    "Y = to_categorical(iris['target'])\n",
    "Y2 = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    X2_train, X2_test = X[train_index], X[test_index]\n",
    "    Y2_train, Y2_test = Y2[train_index], Y2[test_index]\n",
    "    clf.fit(X2_train, Y2_train)\n",
    "    clfTest = clf.predict(X2_test)\n",
    "    print(confusion_matrix(clfTest, Y2_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = Sequential()\n",
    "model.add(Dense(6, input_dim = 13, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'linear'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "opt = optimizers.SGD(learning_rate = 0.1, momentum = 0, nesterov = True)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_training = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(my_model_training.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(my_model_training.history['loss'], label='Loss')\n",
    "plt.plot(my_model_training.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(my_model_training.history['accuracy'], label='Accuracy')\n",
    "plt.plot(my_model_training.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "Y_predicted = np.argmax(y_predicted, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(Y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = boston['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = svm.SVR(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits = 11, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kFold.split(A):\n",
    "    A_train, A_test = A[train_index], A[test_index]\n",
    "    B_train, B_test = B[train_index], B[test_index]\n",
    "    clf2.fit(A_train, B_train)\n",
    "    print(clf2.score(A_test, B_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C, D = diabetes['data'], diabetes['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = svm.SVR(kernel = 'linear')\n",
    "clf4 = svm.SVR(kernel = 'rbf')\n",
    "reg = linear_model.Ridge(alpha=.5)\n",
    "reg2 = linear_model.Lasso(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2Fold = KFold(n_splits = 17, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultLinear = []\n",
    "resultRBF = []\n",
    "resultRidge = []\n",
    "resultLasso = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainKFold(model):\n",
    "    results = []\n",
    "    for train_index, test_index in k2Fold.split(C):\n",
    "        C_train, C_test = C[train_index], C[test_index]\n",
    "        D_train, D_test = D[train_index], D[test_index]\n",
    "        model.fit(C_train, D_train)\n",
    "        results.append(model.score(C_test, D_test))\n",
    "    return sorted(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultLinear = []\n",
    "resultRBF = []\n",
    "resultRidge = []\n",
    "resultLasso = []\n",
    "for i in range(1,11):\n",
    "    currentAlpha = i/100\n",
    "    reg = linear_model.Ridge(alpha=currentAlpha)\n",
    "    resultRidge.append(trainKFold(reg))\n",
    "    \n",
    "    reg2 = linear_model.Lasso(alpha=currentAlpha)\n",
    "    resultLasso.append(trainKFold(reg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Worst:  0.19233191860143417\n",
      "Lasso Worst:  -0.11816097151734128\n",
      "\n",
      "Ridge Worst:  -0.08924611451515263\n",
      "Lasso Worst:  0.03636555709905187\n",
      "\n",
      "Ridge Worst:  0.20280555344083429\n",
      "Lasso Worst:  -0.039142653209591094\n",
      "\n",
      "Ridge Worst:  0.15338703473630777\n",
      "Lasso Worst:  0.24479608579796597\n",
      "\n",
      "Ridge Worst:  -0.012503155945649878\n",
      "Lasso Worst:  0.19841524528425503\n",
      "\n",
      "Ridge Worst:  0.14853265468000365\n",
      "Lasso Worst:  -0.03944256451670847\n",
      "\n",
      "Ridge Worst:  0.15343795597674714\n",
      "Lasso Worst:  0.16545791395357135\n",
      "\n",
      "Ridge Worst:  0.29337735889031635\n",
      "Lasso Worst:  0.10975345112596158\n",
      "\n",
      "Ridge Worst:  0.327595458328811\n",
      "Lasso Worst:  0.06356054998045746\n",
      "\n",
      "Ridge Worst:  0.07030304989782088\n",
      "Lasso Worst:  0.1772426551877445\n",
      "\n",
      "Worst Ridge:  0.327595458328811\n",
      "Worst Lasso:  0.24479608579796597\n",
      "Best Ridge:  0.7607695733527444\n",
      "Best Lasso:  0.7119858077910458\n"
     ]
    }
   ],
   "source": [
    "worstRidge = -1\n",
    "bestRidge = -1\n",
    "worstLasso = -1\n",
    "bestLasso = -1\n",
    "\n",
    "for i in range(len(resultRidge)):\n",
    "    print(\"Ridge Worst: \", resultRidge[i][0])\n",
    "    #print(\"Ridge Middle: \", resultRidge[i][8])\n",
    "    #print(\"Ridge Best: \", resultRidge[i][-1])\n",
    "    print(\"Lasso Worst: \", resultLasso[i][0])\n",
    "    #print(\"Lasso Middle: \", resultLasso[i][8])\n",
    "    #print(\"Lasso Best: \", resultLasso[i][-1])\n",
    "    print()\n",
    "    if(resultRidge[i][0] > worstRidge):\n",
    "        worstRidge = resultRidge[i][0]\n",
    "    if(resultRidge[i][-1] > bestRidge):\n",
    "        bestRidge = resultRidge[i][-1]\n",
    "    if(resultLasso[i][0] > worstLasso):\n",
    "        worstLasso = resultLasso[i][0]\n",
    "    if(resultLasso[i][-1] > bestLasso):\n",
    "        bestLasso = resultLasso[i][-1]\n",
    "    \n",
    "print(\"Worst Ridge: \", worstRidge)\n",
    "print(\"Worst Lasso: \", worstLasso)\n",
    "print(\"Best Ridge: \", bestRidge)\n",
    "print(\"Best Lasso: \", bestLasso)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "alpha = 0.06\n",
    "results.append(trainKFold(clf3))\n",
    "results.append(trainKFold(clf4))\n",
    "reg = linear_model.Ridge(alpha=alpha)\n",
    "results.append(trainKFold(reg))\n",
    "reg2 = linear_model.Lasso(alpha=alpha)\n",
    "results.append(trainKFold(reg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2958930069432122\n",
      "0.022413380904457436\n",
      "0.033704573890780076\n",
      "\n",
      "-0.2904575054609568\n",
      "-0.030124736228503087\n",
      "0.005011232300757618\n",
      "\n",
      "0.23203364808994587\n",
      "0.4717851264223085\n",
      "0.6889839501532519\n",
      "\n",
      "0.23045718964200926\n",
      "0.48631590937520136\n",
      "0.6932759333143618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results)):\n",
    "    print(results[i][0])\n",
    "    print(results[i][8])\n",
    "    print(results[i][-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
